---
title: "Working with ZXY data part 1"
author: "Andreas K. Winther"
date: "5/28/2019"
output: html_document
bibliography: references.bib
csl: apa.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Introduction

In this post we'll calculate some basic tracking metrics using the ZXY data from Pettersen et al 2014. 

```{r echo=FALSE, message=FALSE}
#install.packages("Rcpp", repos = "http://cran.us.r-project.org")
#install.packages("ggforce", repos = "http://cran.us.r-project.org")
#library(ggforce)
library(dplyr)
library(zoo)
library(ggplot2)
```

The data can easily be imported by typing the followig code:
```{r}
df <- read.csv("http://home.ifi.uio.no/paalh/dataset/alfheim/2013-11-03/zxy/2013-11-03_tromso_stromsgodset_first.csv", header = FALSE)
```

Let's start by changing the names of the variables, and adding a column with the time elapsed in seconds.
```{r}
names(df) <- c("timestamp", "tag_id", "x_pos", "y_pos", "heading", "direction", "energy", "speed", "total_distance")

options(digits.secs = 6)
df$timestamp <- as.POSIXct(df$timestamp,format = "%Y-%m-%d %H:%M:%OS")
df$seconds <- as.numeric(df$timestamp - min(df$timestamp))
df$minutes <- df$seconds/60
```

We are also going to add some common tracking metrics, namely cumulative high-intensity distance, cumulative sprint distance, and acceleration. 

```{r}
p1 <- df[df$tag_id == 1,]
bf1 <- butter(3, 0.03, type = "low", plane = "z") 
p1speedfiltered <- filter(bf1, p1$speed)
summary(p1speedfiltered)
summary(p1$speed)

df <- df %>%
  group_by(tag_id) %>%
  mutate(distance = (sqrt((x_pos - lag(x_pos))^2 + (y_pos - lag(y_pos))^2)),
         speed_km.h = (speed * 3.6),
         hir_distance = (cumsum(ifelse(speed_km.h >=19.8 & speed_km.h <= 25.2, distance, 0))),
         sprint_distance = (cumsum(ifelse(speed_km.h > 25.2, distance, 0))),
         speedfiltered = filter(bf1, speed),
         acceleration = c(NA, diff(speed)) / c(NA, diff(timestamp)),
         accelerationFiltered = c(NA, diff(speedfiltered)) / c(NA, diff(timestamp)))

summary(df$speed)
summary(df$speedfiltered)
summary(df$acceleration)
summary(df$accelerationFiltered)
boxplot.stats(df$accelerationFiltered)

```

As showed by @andreassen2019real the number of occurences and the distance covered during events such as sprints, high intensity runs (HIR), and accelerations, can easily be extracted from this kind of data. In said paper these events are defined as follows:
HIR = A run at a speed faster than $5.5\,m.s^{-1}$ or $19.8\,km.h^{-1}$, over a time period of 1 second,
Sprint = A run at a speed faster than $7.0\,m.s^{âˆ’1}$ over a time period greater than 1 seconds is said to be a sprint,
and
Acceleration = a change of speed over $2.0\,m.s^{2}$ over a duration of 0.5 seconds.

To extract these events we're going to use a base R function called "rle" or "run length encoding". Rle captures the "run length" of events, which is useful in our case because we want to capture the duration in which the speed or acceleration is over a certain threshold. This can be done as follows:

```{r}
counter <- function(metric, threshold, timestamp, timeThreshold) {
  metricVector <- vector("numeric", length = length(metric))
  for (i in 1:length(metric)) {
    if (metric[i] > threshold) {
      metricVector[i] = 1
    }
  }
  rleMetric <- rle(metricVector)
  indices <- cumsum(rleMetric$lengths)
  if (length(indices) %% 2 == 1) {
    indices <- c(indices, indices[length(indices)])
  }
  metricStart <- indices[seq(from = 1, to = length(indices), by = 2)]
  metricEnd <- indices[seq(from = 2, to = length(indices), by = 2)]
  metricStartStamp <- timestamp[metricStart]
  metricEndStamp <- timestamp[metricEnd]
  metricTimeDiff <- metricEndStamp - metricStartStamp
  return(sum(metricTimeDiff > timeThreshold))
}
```
What's basically happening here is that the function creates a vector, which we are going to fill with 0s and 1s. Here, 1 represents an index where either the speed or acceleration is above a certian threshold. Next, we run this vector through "rle" which then counts the number of indices with consecutive 0s. When it finds a 1, it starts counting how many this number appears before stumbling upon a zero again. Then it starts counting consecutive zeroes, etc. Next we want the indices where a sprint or acceleration starts or ends. Since "rle" counts, for example, 73 zeroes, 22 ones, 55 zeroes, we can use the cumulative sum over each counted number to get the actually indices. In the given example, a sprint or acceleration starts at index 73 and ends at 95. By sequensing every other index, we extract the start and end of each sprint or acceleration. We then use these vectors to subset the timestamp of start or an and of each sprint and acceleration. By substracting the start of a metric from the end we then get the time difference. Finally we filter out all the sprints or acceleration which to not meet the time threshold, and count the number we are left with, giving us the number of sprint or accelerations in the dataset.    

Now, let's use this function to find how many accelerations and sprints some players did in the first half:

```{r}
df %>%
  group_by(tag_id) %>%
  summarise(accelerations = counter(na.omit(accelerationFiltered), 2, timestamp, 0.5), 
            sprints = counter(speedfiltered, 7, timestamp, 1))  
```

The number of sprints are basically the same as reported in @pettersen2018quantified, @baptista2018position, @ingebrigtsen2015acceleration, and @dalen2016player. However, accelerations differ by quite alot... ~205-251 vs. ~38-45. Tinkering with the time threshold makes it a little better: 
```{r}
df %>%
  group_by(tag_id) %>%
  summarise(accelerations = counter(na.omit(acceleration), 2, timestamp, 0.85), 
            sprints = counter(speed, 7, timestamp, 1)) %>%
  filter(tag_id %in% c(1,7,9))
```

Other common metrics such as sprint and acceleration distance, and sprint and acceleration workrate (distance per minute), can be derived as follows: 

```{r}
metricDistance <- function(metric, metricThreshold, timestamp, distance, timeThreshold) {
  metricVector <- vector("numeric", length = length(metric))
  for (i in 1:length(metric)) {
    if (metric[i] >= metricThreshold) {
      metricVector[i] = 1
    }
  }
  metricIndex <- rle(metricVector)
  metricIndexes <- cumsum(metricIndex$lengths)
  if (length(metricIndexes) %% 2 == 1) {
    metricIndexes <- c(metricIndexes, metricIndexes[length(metricIndexes)])
  }
  metricStart <- metricIndexes[seq(from = 1, to = length(metricIndexes), by = 2)]
  metricEnd <- metricIndexes[seq(from = 2, to = length(metricIndexes), by = 2)]
  metricStartStamp <- timestamp[metricStart] #Subsets indices in "timestamp"" where a sprint or acceleration starts
  metricEndStamp <- timestamp[metricEnd] #Subsets indices in "timestamp" where" a sprint or acceleration ends 
  metricDistStartStamp <- distance[metricStart] #Subsets indices in "distance" where a sprint or acceleration starts
  metricDistEndStamp <- distance[metricEnd] #Subsets indices in "distance" where a sprint or acceleration ends
  metricTimeDiff <- metricEndStamp - metricStartStamp #Calculates the time between sprint/accleration start and end
  metricDistDiff <- metricDistEndStamp - metricDistStartStamp #Calculates the distance between sprint/acceleration start and end
  return(sum(metricDistDiff[metricTimeDiff >= timeThreshold])) #Returns the total distance of sprint/accelerations where the time is over a certian threshold
}

df %>%
  group_by(tag_id) %>%
  summarise(accelDist = metricDistance(na.omit(accelerationFiltered), 2, timestamp, total_distance, 0.5),
            sprintDist = metricDistance(speedfiltered, 7, timestamp, total_distance, 1),
            workRateAccel = accelDist/max(minutes),
            workRateSprint = sprintDist/max(minutes)) #%>%
  filter(tag_id %in% c(1,7,9))
```


```{r}
sprintDistance <- function(speed, speedThreshold, timestamp, distance, timeThreshold, meterStart, meterEnd) {
  sprintVector <- vector("numeric", length = length(speed))
  for (i in 1:length(speed)) {
    if (speed[i] > speedThreshold) {
      sprintVector[i] = 1
    }
  }
  sprintIndex <- rle(sprintVector)
  sprintIndexes <- cumsum(sprintIndex$lengths)
  if (length(sprintIndexes) %% 2 == 1) {
    sprintIndexes <- c(sprintIndexes, sprintIndexes[length(sprintIndexes)])
  }
  sprintStart <- sprintIndexes[seq(from = 1, to = length(sprintIndexes), by = 2)]
  sprintEnd <- sprintIndexes[seq(from = 2, to = length(sprintIndexes), by = 2)]
  sprintStartStamp <- timestamp[sprintStart] #Subsets timestamp indexes where a sprint starts
  sprintEndStamp <- timestamp[sprintEnd] #Subsets timestamp indexes where a sprint ends
  sprintDistStartStamp <- distance[sprintStart] #Subsets distance indexes where a sprint starts 
  sprintDistEndStamp <- distance[sprintEnd] #Subsets distance indexes where a sprint ends 
  sprintTimeDiff <- sprintEndStamp - sprintStartStamp #Calculates the time difference between sprint start and end
  sprintDistDiff <- sprintDistEndStamp - sprintDistStartStamp
  sprintDistDiff <- sprintDistDiff >= meterStart & sprintDistDiff <= meterEnd
  return(sum(sprintDistDiff[sprintTimeDiff > timeThreshold]))
}

df %>%
  group_by(tag_id) %>%
  summarise(sprintMeters1_5 = sprintDistance(speedfiltered, 7, timestamp, total_distance, 0, 1, 5),
            sprintMeters6_10 = sprintDistance(speedfiltered, 7, timestamp, total_distance, 0, 6, 10),
            sprintMeters11_15 = sprintDistance(speedfiltered, 7, timestamp, total_distance, 0, 11, 15),
            sprintMeters16_20 = sprintDistance(speedfiltered, 7, timestamp, total_distance, 0, 16, 20),
            sprintMeters21_25 = sprintDistance(speedfiltered, 7, timestamp, total_distance, 0, 21, 25),
            sprintMeters26_30 = sprintDistance(speedfiltered, 7, timestamp, total_distance, 0, 26, 30),
            sprintMeters31_35 = sprintDistance(speedfiltered, 7, timestamp, total_distance, 0, 31, 35),
            sprintMeters36_40 = sprintDistance(speedfiltered, 7, timestamp, total_distance, 0, 36, 40),
            sprintMeters41plus = sprintDistance(speedfiltered, 7, timestamp, total_distance, 0, 41, 80)) # %>%
  filter(tag_id %in% c(2,5,7,8,9,10,13,14,15,1))
```

###Metabolic power

Another interesting metric is metabolic power:
```{r}

df <- df %>%
  group_by(tag_id) %>%
  mutate(alpha = rad2deg(atan(9.81/acceleration)),
         g = sqrt(acceleration^2 + 9.81^2),
         equivilantSlope = tan(0.5 * pi - atan(9.81/acceleration)),
         equivilantMass = g/9.81,
         energyCost = ifelse(acceleration == 0, 3.6*1.29, (155.4*equivilantSlope^5 - 30.4*equivilantSlope^4 - 43.3*equivilantSlope^3 + 46.3*equivilantSlope^2 + 19.5*equivilantSlope + 3.6)*equivilantMass*1.29),
         metabolicPower = energyCost*speed)

summary(df$metabolicPower)
boxplot.stats(df$metabolicPower)
hist(df$metabolicPower, freq = FALSE)
sum(df$metabolicPower > 70, na.rm = TRUE)
median(df$metabolicPower, na.rm = TRUE)
median(df$energyCost, na.rm = TRUE)
```

##Clustering
As showed by @sweeting2017discovering rather than using pre-determined metric threshold, one can instead use machine learning to determine these threshold up with x-number of threshold. In the mentioned paper they used what is know as k-means clustering. This technique works by iterating over a set of observations (velocity data) and a set number of groups (n = 4). The k-means algorithm finds the center of each group, allocating each data point based on the closest center and iteratively (re)assigning the center until each data point within the set is allocated. The following function can be used to determined clusters for any metric: 

```{r}
clusters <- function(x,y) {
  clusterMatrix <- as.matrix(x[!is.na(x)], ncol = 1)
  nClusters <- y
  set.seed(1)
  k.clusters <- kmeans(clusterMatrix[,1], nClusters)
  return(k.clusters)
}  

accelerationClusters <- clusters(df$acceleration, 3)
metPowClusters <- clusters(df$metabolicPower, 1)

accelClusters$centers
format(metPowClusters$centers, scientific = F)

# Heading cluster
df$headingCluster <- headingClusters$cluster
df$headingNotational <- factor(headingClusters$cluster, levels = 1:length(headingClusters$centers), labels = c("Left turn", "Straight", "Right turn"))

df$directionCluster <- directionClusters$cluster
df$directionNotational <- factor(directionClusters$cluster, levels = 1:length(directionClusters$centers), labels = c("-2", "1", "2", "0"))

# Angular disp clusters
df$angularDispClusters <- NA
df$angularDispClusters[which(!is.na(df$angularDisp))] <- angularDispClusters$cluster
df$angularDispNotational <- factor(df$angularDispClusters, levels = 1:length(angularDispClusters$centers), labels = c("0.3", "2.2", "0.0", "0.1", "0.85"))

# Angular velocity clusters
df$angularVelocityClusters <- NA
df$angularVelocityClusters[which(!is.na(df$angularVeloctiy))] <- angularVelocityClusters$cluster
df$angularVelocityNotational <- factor(df$angularVelocityClusters, levels = 1:length(angularVelocityClusters$centers), labels = c("Straight", "1", "2", "3"))
      
df$accelNotational <- factor(accelClusters$cluster, levels = 1:length(accelClusters$centers), labels = c("Neutral", "Deceleration", "Acceleration")) #c(as.character(round(accelClusters$centers, 1))))

player1 <- df[df$tag_id == 1,]
player1_200_380 <- player1[player1$seconds >200 & player1$seconds < 380,]

# Create a new column, based on "Centers" data.frame
ggplot(data = df_cleaned, aes(x = NotationalDescriptor, fill = NotationalDescriptor)) +
geom_bar(colour = "black", size = 1) +
xlab("\n Notational Descriptor") +
ylab("Count \n") +
scale_y_continuous() +
theme_classic() +
theme(legend.position = "none")

# Plot based on the notational descriptor
ggplot(data = player1, aes(x = seconds, y = angularDisp, color = NotationalDescriptor, group = 1)) +
geom_line() +
scale_color_manual(values = c("green", "red", "black", "blue")) + 
xlab("\n Time (s)") +
ylab(expression(Velocity ~ (m.s^-1))) +
scale_x_continuous(limits = c(200, 380), breaks = seq(200, 380, by = 20)) +
scale_y_continuous() +
# The line of code below changes the legend heading, when we wish to add a space between words
labs(colour = 'Notational Descriptor') +
theme_classic() +
theme(legend.position = "bottom")  



ggplot(player1_200_380) +
  #geom_path(aes(x = x_pos, y = y_pos, color = turns)) +
  geom_path(aes(x = x_pos, y = y_pos, color = angularDispNotational, group = 1)) +
  scale_color_discrete() +
  #scale_color_gradientn(colors = rainbow(7)) +
  theme_minimal()



```